{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb401f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95350d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# model result saving\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "# import my utils\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src import data_utils, models\n",
    "\n",
    "# Import the evaluation utilities\n",
    "from src.active_learning import ModelEvaluator, compare_learning_strategies, ActiveLearningEvaluator\n",
    "from src.metrics import compute_computational_savings, find_convergence_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bce193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure data has been generated\n",
    "if not os.path.exists('../datasets/synfunc.csv'):\n",
    "    data_utils.generate_synthetic_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acb19a",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f496b0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "422bc73d-ae8b-421f-9846-f4e0df3e3e2c",
       "rows": [
        [
         "0",
         "0.1541628423796723",
         "0.933592079256112"
        ],
        [
         "1",
         "0.7400496965154048",
         "-1.119465903092363"
        ],
        [
         "2",
         "0.2633150151851346",
         "1.0924989725928322"
        ],
        [
         "3",
         "0.5337393933802977",
         "-0.3271866456526417"
        ],
        [
         "4",
         "0.0145749624854196",
         "0.0580402541774215"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154163</td>\n",
       "      <td>0.933592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.740050</td>\n",
       "      <td>-1.119466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.263315</td>\n",
       "      <td>1.092499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.533739</td>\n",
       "      <td>-0.327187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014575</td>\n",
       "      <td>0.058040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.154163  0.933592\n",
       "1  0.740050 -1.119466\n",
       "2  0.263315  1.092499\n",
       "3  0.533739 -0.327187\n",
       "4  0.014575  0.058040"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/synfunc.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d403cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "35739030-78a9-4117-b402-5e755409b227",
       "rows": [
        [
         "x",
         "0"
        ],
        [
         "y",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "x    0\n",
       "y    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0162b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128111d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  5., 13., 18., 25., 23., 30., 25., 16., 14., 12., 20., 10.,\n",
       "         9., 16., 19., 11.,  8., 10., 13., 17., 13., 16., 19., 16., 29.,\n",
       "        32., 30., 19., 10.]),\n",
       " array([-1.27849613, -1.19681391, -1.11513169, -1.03344947, -0.95176725,\n",
       "        -0.87008503, -0.78840281, -0.70672059, -0.62503837, -0.54335615,\n",
       "        -0.46167392, -0.3799917 , -0.29830948, -0.21662726, -0.13494504,\n",
       "        -0.05326282,  0.0284194 ,  0.11010162,  0.19178384,  0.27346606,\n",
       "         0.35514828,  0.43683051,  0.51851273,  0.60019495,  0.68187717,\n",
       "         0.76355939,  0.84524161,  0.92692383,  1.00860605,  1.09028827,\n",
       "         1.17197049]),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# histogram of y\n",
    "plt.hist(df['y'], bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e645f60c",
   "metadata": {},
   "source": [
    "### 1. Scale features to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab653074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'generate_synthetic_data', 'np', 'pd', 'scale_min_max', 'scale_z_score']\n"
     ]
    }
   ],
   "source": [
    "print(dir(data_utils))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddeffe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9dab1db2-3893-421e-b31e-c2b5c54a90d8",
       "rows": [
        [
         "0",
         "-0.6952830280088512",
         "0.933592079256112"
        ],
        [
         "1",
         "0.4799995703449371",
         "-1.119465903092363"
        ],
        [
         "2",
         "-0.47632496748024644",
         "1.0924989725928322"
        ],
        [
         "3",
         "0.06614336684047584",
         "-0.3271866456526417"
        ],
        [
         "4",
         "-0.9752947828771507",
         "0.0580402541774215"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.695283</td>\n",
       "      <td>0.933592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480000</td>\n",
       "      <td>-1.119466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.476325</td>\n",
       "      <td>1.092499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066143</td>\n",
       "      <td>-0.327187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.975295</td>\n",
       "      <td>0.058040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0 -0.695283  0.933592\n",
       "1  0.480000 -1.119466\n",
       "2 -0.476325  1.092499\n",
       "3  0.066143 -0.327187\n",
       "4 -0.975295  0.058040"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale features to [-1, 1]\n",
    "feature_cols = df.columns[:-1]  # all columns except the last 1 (one-hot encoded target)\n",
    "\n",
    "df[feature_cols] = data_utils.scale_min_max(df[feature_cols], min_val=-1, max_val=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928fc1bb",
   "metadata": {},
   "source": [
    "### 2. Prepare X and Y matrices and tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a954a241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "7b667541-53e0-4603-9739-2c43bd3a141a",
       "rows": [
        [
         "0",
         "0.933592079256112"
        ],
        [
         "1",
         "-1.119465903092363"
        ],
        [
         "2",
         "1.0924989725928322"
        ],
        [
         "3",
         "-0.3271866456526417"
        ],
        [
         "4",
         "0.0580402541774215"
        ],
        [
         "5",
         "-0.4058952208000274"
        ],
        [
         "6",
         "-0.4976438858272748"
        ],
        [
         "7",
         "0.1229125817585481"
        ],
        [
         "8",
         "-0.260027073288087"
        ],
        [
         "9",
         "0.6466230704633508"
        ],
        [
         "10",
         "0.9568652662685856"
        ],
        [
         "11",
         "-0.576112455105585"
        ],
        [
         "12",
         "-0.398543647564465"
        ],
        [
         "13",
         "-0.6506899945333262"
        ],
        [
         "14",
         "0.0637872974459941"
        ],
        [
         "15",
         "-0.0647047193507261"
        ],
        [
         "16",
         "-0.3777052236401655"
        ],
        [
         "17",
         "0.0785666682035667"
        ],
        [
         "18",
         "-0.9634284415544412"
        ],
        [
         "19",
         "0.9335084078736674"
        ],
        [
         "20",
         "-0.9250018261828692"
        ],
        [
         "21",
         "0.0898712862146229"
        ],
        [
         "22",
         "0.6670667945376489"
        ],
        [
         "23",
         "0.5488519479277925"
        ],
        [
         "24",
         "1.1439675358568486"
        ],
        [
         "25",
         "-0.7671115048211329"
        ],
        [
         "26",
         "0.3252557845291589"
        ],
        [
         "27",
         "-0.9295374972923868"
        ],
        [
         "28",
         "1.1719704945176213"
        ],
        [
         "29",
         "-0.942957169705197"
        ],
        [
         "30",
         "-0.932221879064413"
        ],
        [
         "31",
         "0.8309962274111332"
        ],
        [
         "32",
         "0.7206920952712806"
        ],
        [
         "33",
         "-0.0691372984389283"
        ],
        [
         "34",
         "-0.6977757865569746"
        ],
        [
         "35",
         "-0.3075060244054224"
        ],
        [
         "36",
         "-1.1288692471356063"
        ],
        [
         "37",
         "-1.0911990595657852"
        ],
        [
         "38",
         "0.4425443786642875"
        ],
        [
         "39",
         "0.3898632126431546"
        ],
        [
         "40",
         "0.7749637211406187"
        ],
        [
         "41",
         "-0.0957809009496391"
        ],
        [
         "42",
         "0.8652634065064045"
        ],
        [
         "43",
         "-0.3898577252861785"
        ],
        [
         "44",
         "0.3846928641621991"
        ],
        [
         "45",
         "0.4912636443886468"
        ],
        [
         "46",
         "0.152156813984278"
        ],
        [
         "47",
         "0.722959529635579"
        ],
        [
         "48",
         "0.338277499448173"
        ],
        [
         "49",
         "0.200414094563839"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 500
       }
      },
      "text/plain": [
       "0      0.933592\n",
       "1     -1.119466\n",
       "2      1.092499\n",
       "3     -0.327187\n",
       "4      0.058040\n",
       "         ...   \n",
       "495    0.973097\n",
       "496   -0.794886\n",
       "497    0.651283\n",
       "498    0.620207\n",
       "499   -0.114651\n",
       "Name: y, Length: 500, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138678ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = df[feature_cols].values\n",
    "y = df['y'].values.reshape(-1, 1)\n",
    "y_raw = y.copy()\n",
    "\n",
    "\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72957b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matplotlib to Times New Roman font\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16161bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0bcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35424424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc43341d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded best parameters:\n",
      "Best parameters: {'hidden_size': 64, 'learning_rate': 0.5, 'weight_decay': 0.0, 'momentum': 0.95, 'train_mse': 0.010937669314444065, 'test_mse': 0.011201427318155766, 'train_r2': 0.978721022605896, 'test_r2': 0.9779318571090698}\n"
     ]
    }
   ],
   "source": [
    "results_dir = \"../results/synfunc\"\n",
    "best_params_filename = os.path.join(results_dir, \"best_hyperparameters.pkl\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(best_params_filename):\n",
    "    with open(best_params_filename, 'rb') as f:\n",
    "        loaded_best_params = pickle.load(f)\n",
    "    \n",
    "    print(\"Successfully loaded best parameters:\")\n",
    "    print(f\"Best parameters: {loaded_best_params}\")\n",
    "    \n",
    "    # Verify they match the current best_params\n",
    "    if 'best_params' in locals():\n",
    "        print(f\"Parameters match current session: {best_params == loaded_best_params}\")\n",
    "    \n",
    "    # Use loaded parameters (in case we're running this cell independently)\n",
    "    best_params = loaded_best_params\n",
    "    \n",
    "else:\n",
    "    print(f\"Best parameters file not found at: {best_params_filename}\")\n",
    "    print(\"Make sure to run the hyperparameter search first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15737732",
   "metadata": {},
   "source": [
    "#### Add input and output sizes to params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e86abca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correct input and output sizes for regression\n",
    "best_params['input_size'] = 1  # Single input feature (x)\n",
    "best_params['output_size'] = 1  # Single output value (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172b2197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13e55f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created RegressionModelEvaluator with Cross-Validation support!\n",
      "✓ Supports both CV and simple train-test splits\n",
      "✓ Uses KFold (no stratification) for regression\n",
      "✓ Uses MSE-based metrics instead of classification metrics\n",
      "✓ Overrides evaluate_passive_learning to handle regression data\n",
      "✓ Includes gradient clipping (max_norm=1.0) to match original training\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Use AdaptiveNet (recommended - minimal code changes)\n",
    "# This model can handle both classification and regression\n",
    "\n",
    "# First, let's patch the active learning code to use AdaptiveNet for regression\n",
    "# This is a simple monkey patch that requires minimal changes\n",
    "\n",
    "# Save the original NeuralNet import\n",
    "from src.models import AdaptiveNet\n",
    "from sklearn.model_selection import KFold  # For regression CV (no stratification)\n",
    "\n",
    "# Create a custom ModelEvaluator for regression\n",
    "class RegressionModelEvaluator(ModelEvaluator):\n",
    "    def evaluate_passive_learning(self, X, y, best_params, n_trials=50,\n",
    "                                 use_cv=True, cv_folds=5, epochs=1000, \n",
    "                                 random_state=42, model_class=None):\n",
    "        \"\"\"\n",
    "        Override to handle regression data (no one-hot encoding).\n",
    "        \n",
    "        Args:\n",
    "            X: Input features tensor\n",
    "            y: Target values tensor (continuous values, not one-hot)\n",
    "            best_params: Dictionary with best hyperparameters\n",
    "            n_trials: Number of trials to run\n",
    "            use_cv: Whether to use cross-validation\n",
    "            cv_folds: Number of CV folds\n",
    "            epochs: Maximum epochs per trial\n",
    "            random_state: Base random state\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with comprehensive evaluation results\n",
    "        \"\"\"\n",
    "        print(f\"Starting {n_trials} trial evaluation...\")\n",
    "        print(f\"Parameters: {best_params}\")\n",
    "        print(f\"Cross-validation: {'Yes' if use_cv else 'No'} ({cv_folds} folds)\")\n",
    "        \n",
    "        self.metrics_tracker.reset()\n",
    "        \n",
    "        # For regression, y is already continuous values, no need to convert\n",
    "        # Use y directly as indices (dummy variable for compatibility)\n",
    "        y_indices = y\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            print(f\"Trial {trial + 1}/{n_trials}\", end=\"... \")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            if use_cv:\n",
    "                # Cross-validation approach\n",
    "                trial_results = self._run_cv_trial(X, y, y_indices, best_params, \n",
    "                                                 cv_folds, epochs, random_state + trial, model_class)\n",
    "            else:\n",
    "                # Simple train-test split approach\n",
    "                trial_results = self._run_simple_trial(X, y, y_indices, best_params, \n",
    "                                                     epochs, random_state + trial, model_class)\n",
    "            \n",
    "            computation_time = time.time() - start_time\n",
    "            \n",
    "            # Add results to tracker\n",
    "            self.metrics_tracker.add_trial_results(\n",
    "                train_acc=trial_results['train_acc'],\n",
    "                test_acc=trial_results['test_acc'],\n",
    "                val_acc=trial_results.get('val_acc'),\n",
    "                losses=trial_results['losses'],\n",
    "                val_losses=trial_results.get('val_losses'),\n",
    "                epochs_converged=trial_results['epochs_converged'],\n",
    "                num_presentations=trial_results['num_presentations'],\n",
    "                computation_time=computation_time,\n",
    "                train_metrics=trial_results.get('train_metrics'),\n",
    "                test_metrics=trial_results.get('test_metrics'),\n",
    "                val_metrics=trial_results.get('val_metrics'),\n",
    "                train_acc_curve=trial_results.get('train_acc_curve'),\n",
    "                test_acc_curve=trial_results.get('test_acc_curve')\n",
    "            )\n",
    "            \n",
    "            print(f\"Test MSE: {-trial_results['test_acc']:.4f}, Time: {computation_time:.2f}s\")\n",
    "        \n",
    "        # Compute and return comprehensive statistics\n",
    "        results = self.metrics_tracker.compute_statistics()\n",
    "        results['learning_type'] = 'passive'\n",
    "        results['best_params'] = best_params\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _train_model(self, X_train, y_train_idx, X_test, y_test_idx, params, epochs):\n",
    "        \"\"\"Override to use AdaptiveNet for regression\"\"\"\n",
    "        \n",
    "        # Use AdaptiveNet configured for regression\n",
    "        model = AdaptiveNet(\n",
    "            input_size=params.get('input_size', 1),\n",
    "            hidden_size=params['hidden_size'],\n",
    "            output_size=params.get('output_size', 1),\n",
    "            use_mse=False,  # We'll use MSE loss externally\n",
    "            task_type='regression'\n",
    "        )\n",
    "        \n",
    "        # Use MSE loss for regression\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=params['learning_rate'],\n",
    "            weight_decay=params['weight_decay'],\n",
    "            momentum=params.get('momentum', 0.0)\n",
    "        )\n",
    "        \n",
    "        # For regression, targets are already in the right format (continuous values)\n",
    "        # Convert indices to float if they aren't already\n",
    "        y_train_target = y_train_idx.float().unsqueeze(1) if y_train_idx.dim() == 1 else y_train_idx.float()\n",
    "        y_test_target = y_test_idx.float().unsqueeze(1) if y_test_idx.dim() == 1 else y_test_idx.float()\n",
    "        \n",
    "        # Training loop\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        train_acc_curve = []\n",
    "        test_acc_curve = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training step\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train_target)\n",
    "            loss.backward()\n",
    "            \n",
    "            # IMPORTANT: Add gradient clipping to match original training!\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Validation step\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_test)\n",
    "                val_loss = criterion(val_outputs, y_test_target)\n",
    "                val_losses.append(val_loss.item())\n",
    "                \n",
    "                # For regression, use negative MSE as \"accuracy\" (higher is better)\n",
    "                train_outputs = model(X_train)\n",
    "                train_mse = nn.MSELoss()(train_outputs, y_train_target)\n",
    "                test_mse = nn.MSELoss()(val_outputs, y_test_target)\n",
    "                \n",
    "                train_epoch_acc = -train_mse.item()\n",
    "                test_epoch_acc = -test_mse.item()\n",
    "                \n",
    "                train_acc_curve.append(train_epoch_acc)\n",
    "                test_acc_curve.append(test_epoch_acc)\n",
    "        \n",
    "        # Find convergence epoch\n",
    "        epochs_converged = find_convergence_epoch(losses)\n",
    "        \n",
    "        # Final evaluation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_outputs = model(X_train)\n",
    "            test_outputs = model(X_test)\n",
    "            \n",
    "            train_mse = nn.MSELoss()(train_outputs, y_train_target)\n",
    "            test_mse = nn.MSELoss()(test_outputs, y_test_target)\n",
    "            \n",
    "            train_acc = -train_mse.item()\n",
    "            test_acc = -test_mse.item()\n",
    "            \n",
    "            # Create dummy metrics for regression (since classification metrics don't apply)\n",
    "            train_metrics = {'accuracy': train_acc, 'f1_score': train_acc, 'precision': train_acc, 'recall': train_acc}\n",
    "            test_metrics = {'accuracy': test_acc, 'f1_score': test_acc, 'precision': test_acc, 'recall': test_acc}\n",
    "        \n",
    "        return model, losses, train_acc, test_acc, epochs_converged, train_metrics, test_metrics, val_losses, train_acc_curve, test_acc_curve\n",
    "\n",
    "    def _run_cv_trial(self, X, y, y_indices, params, cv_folds, epochs, random_state, model_class=None):\n",
    "        \"\"\"Override CV trial for regression - no stratification needed\"\"\"\n",
    "        \n",
    "        # First, create a holdout test set\n",
    "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Use regular KFold instead of StratifiedKFold for regression\n",
    "        kfold = KFold(n_splits=cv_folds, shuffle=True, random_state=random_state)\n",
    "        \n",
    "        # Cross-validation metrics tracking\n",
    "        cv_train_accs = []\n",
    "        cv_val_accs = []\n",
    "        cv_train_metrics = []\n",
    "        cv_val_metrics = []\n",
    "        all_losses = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(X_temp)):\n",
    "            X_train = X_temp[train_idx]\n",
    "            X_val = X_temp[val_idx]\n",
    "            y_train = y_temp[train_idx]\n",
    "            y_val = y_temp[val_idx]\n",
    "            \n",
    "            # Train model (y_train and y_val are already continuous values)\n",
    "            model, losses, train_acc, val_acc, _, train_metrics, val_metrics, val_losses, _, _ = self._train_model(\n",
    "                X_train, y_train, X_val, y_val, params, epochs\n",
    "            )\n",
    "            \n",
    "            cv_train_accs.append(train_acc)\n",
    "            cv_val_accs.append(val_acc)\n",
    "            cv_train_metrics.append(train_metrics)\n",
    "            cv_val_metrics.append(val_metrics)\n",
    "            all_losses.extend(losses)\n",
    "        \n",
    "        # Average CV results\n",
    "        avg_train_acc = np.mean(cv_train_accs)\n",
    "        avg_val_acc = np.mean(cv_val_accs)\n",
    "        \n",
    "        # Average CV metrics\n",
    "        avg_train_metrics = self._average_metrics(cv_train_metrics)\n",
    "        avg_val_metrics = self._average_metrics(cv_val_metrics)\n",
    "        \n",
    "        # Final test on holdout set using best parameters\n",
    "        # Train on all temp data for final test\n",
    "        final_model, final_losses, _, _, epochs_converged, _, test_metrics, final_val_losses, train_acc_curve, test_acc_curve = self._train_model(\n",
    "            X_temp, y_temp, X_test, y_test, params, epochs\n",
    "        )\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        final_model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = final_model(X_test)\n",
    "            test_target = y_test.float().unsqueeze(1) if y_test.dim() == 1 else y_test.float()\n",
    "            test_mse = nn.MSELoss()(test_outputs, test_target)\n",
    "            test_acc = -test_mse.item()  # Use negative MSE as \"accuracy\"\n",
    "        \n",
    "        # Calculate pattern presentations\n",
    "        num_presentations = len(X_temp) * epochs_converged\n",
    "        \n",
    "        return {\n",
    "            'train_acc': avg_train_acc,\n",
    "            'val_acc': avg_val_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'losses': all_losses,\n",
    "            'val_losses': final_val_losses,\n",
    "            'train_metrics': avg_train_metrics,\n",
    "            'val_metrics': avg_val_metrics,\n",
    "            'test_metrics': test_metrics,\n",
    "            'epochs_converged': epochs_converged,\n",
    "            'num_presentations': num_presentations,\n",
    "            'train_acc_curve': train_acc_curve,\n",
    "            'test_acc_curve': test_acc_curve\n",
    "        }\n",
    "    \n",
    "    def _run_simple_trial(self, X, y, y_indices, params, epochs, random_state, model_class=None):\n",
    "        \"\"\"Override simple trial for regression\"\"\"\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model, losses, train_acc, test_acc, epochs_converged, train_metrics, test_metrics, val_losses, train_acc_curve, test_acc_curve = self._train_model(\n",
    "            X_train, y_train, X_test, y_test, params, epochs\n",
    "        )\n",
    "        \n",
    "        # Calculate pattern presentations\n",
    "        num_presentations = len(X_train) * epochs_converged\n",
    "        \n",
    "        return {\n",
    "            'train_acc': train_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'losses': losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_metrics': train_metrics,\n",
    "            'test_metrics': test_metrics,\n",
    "            'epochs_converged': epochs_converged,\n",
    "            'num_presentations': num_presentations,\n",
    "            'train_acc_curve': train_acc_curve,\n",
    "            'test_acc_curve': test_acc_curve\n",
    "        }\n",
    "\n",
    "print(\"Created RegressionModelEvaluator with Cross-Validation support!\")\n",
    "print(\"✓ Supports both CV and simple train-test splits\")\n",
    "print(\"✓ Uses KFold (no stratification) for regression\")\n",
    "print(\"✓ Uses MSE-based metrics instead of classification metrics\")\n",
    "print(\"✓ Overrides evaluate_passive_learning to handle regression data\")\n",
    "print(\"✓ Includes gradient clipping (max_norm=1.0) to match original training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f7796",
   "metadata": {},
   "source": [
    "#### Run 50 trials with best control parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9d9ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 50 trials with best parameters and 5-fold cross-validation...\n",
      "Data shapes: X=torch.Size([500, 1]), y=torch.Size([500])\n",
      "Best params from original training: {'hidden_size': 64, 'learning_rate': 0.5, 'weight_decay': 0.0, 'momentum': 0.95, 'train_mse': 0.010937669314444065, 'test_mse': 0.011201427318155766, 'train_r2': 0.978721022605896, 'test_r2': 0.9779318571090698, 'input_size': 1, 'output_size': 1}\n",
      "\n",
      "Starting 50 trial evaluation...\n",
      "Parameters: {'hidden_size': 64, 'learning_rate': 0.5, 'weight_decay': 0.0, 'momentum': 0.95, 'train_mse': 0.010937669314444065, 'test_mse': 0.011201427318155766, 'train_r2': 0.978721022605896, 'test_r2': 0.9779318571090698, 'input_size': 1, 'output_size': 1}\n",
      "Cross-validation: No (5 folds)\n",
      "Trial 1/50... Test MSE: 0.1725, Time: 1.22s\n",
      "Trial 2/50... Test MSE: 0.1725, Time: 1.22s\n",
      "Trial 2/50... Test MSE: 0.2471, Time: 0.48s\n",
      "Trial 3/50... Test MSE: 0.2471, Time: 0.48s\n",
      "Trial 3/50... Test MSE: 0.0101, Time: 0.45s\n",
      "Trial 4/50... Test MSE: 0.0101, Time: 0.45s\n",
      "Trial 4/50... Test MSE: 0.2365, Time: 0.45s\n",
      "Trial 5/50... Test MSE: 0.2365, Time: 0.45s\n",
      "Trial 5/50... Test MSE: 0.0218, Time: 0.44s\n",
      "Trial 6/50... Test MSE: 0.0218, Time: 0.44s\n",
      "Trial 6/50... Test MSE: 0.0092, Time: 0.44s\n",
      "Trial 7/50... Test MSE: 0.0092, Time: 0.44s\n",
      "Trial 7/50... Test MSE: 0.0113, Time: 0.43s\n",
      "Trial 8/50... Test MSE: 0.0113, Time: 0.43s\n",
      "Trial 8/50... Test MSE: 0.0114, Time: 0.44s\n",
      "Trial 9/50... Test MSE: 0.0114, Time: 0.44s\n",
      "Trial 9/50... Test MSE: 0.0087, Time: 0.44s\n",
      "Trial 10/50... Test MSE: 0.0087, Time: 0.44s\n",
      "Trial 10/50... Test MSE: 0.2182, Time: 0.44s\n",
      "Trial 11/50... Test MSE: 0.2182, Time: 0.44s\n",
      "Trial 11/50... Test MSE: 0.0101, Time: 0.44s\n",
      "Trial 12/50... Test MSE: 0.0101, Time: 0.44s\n",
      "Trial 12/50... Test MSE: 0.0114, Time: 0.44s\n",
      "Trial 13/50... Test MSE: 0.0114, Time: 0.44s\n",
      "Trial 13/50... Test MSE: 0.0108, Time: 0.46s\n",
      "Trial 14/50... Test MSE: 0.0108, Time: 0.46s\n",
      "Trial 14/50... Test MSE: 0.0330, Time: 0.50s\n",
      "Trial 15/50... Test MSE: 0.0330, Time: 0.50s\n",
      "Trial 15/50... Test MSE: 0.0114, Time: 0.49s\n",
      "Trial 16/50... Test MSE: 0.0114, Time: 0.49s\n",
      "Trial 16/50... Test MSE: 0.0134, Time: 0.45s\n",
      "Trial 17/50... Test MSE: 0.0134, Time: 0.45s\n",
      "Trial 17/50... Test MSE: 0.2152, Time: 0.47s\n",
      "Trial 18/50... Test MSE: 0.2152, Time: 0.47s\n",
      "Trial 18/50... Test MSE: 0.0116, Time: 0.46s\n",
      "Trial 19/50... Test MSE: 0.0116, Time: 0.46s\n",
      "Trial 19/50... Test MSE: 0.0098, Time: 0.45s\n",
      "Trial 20/50... Test MSE: 0.0098, Time: 0.45s\n",
      "Trial 20/50... Test MSE: 0.0165, Time: 0.46s\n",
      "Trial 21/50... Test MSE: 0.0165, Time: 0.46s\n",
      "Trial 21/50... Test MSE: 0.0102, Time: 0.50s\n",
      "Trial 22/50... Test MSE: 0.0102, Time: 0.50s\n",
      "Trial 22/50... Test MSE: 0.2264, Time: 0.49s\n",
      "Trial 23/50... Test MSE: 0.2264, Time: 0.49s\n",
      "Trial 23/50... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params from original training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m---> 13\u001b[0m passive_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_passive_learning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use properly formatted y\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Print comprehensive report\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 53\u001b[0m, in \u001b[0;36mRegressionModelEvaluator.evaluate_passive_learning\u001b[0;34m(self, X, y, best_params, n_trials, use_cv, cv_folds, epochs, random_state, model_class)\u001b[0m\n\u001b[1;32m     49\u001b[0m     trial_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_cv_trial(X, y, y_indices, best_params, \n\u001b[1;32m     50\u001b[0m                                      cv_folds, epochs, random_state \u001b[38;5;241m+\u001b[39m trial, model_class)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Simple train-test split approach\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     trial_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_simple_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m computation_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Add results to tracker\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 252\u001b[0m, in \u001b[0;36mRegressionModelEvaluator._run_simple_trial\u001b[0;34m(self, X, y, y_indices, params, epochs, random_state, model_class)\u001b[0m\n\u001b[1;32m    247\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[1;32m    248\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom_state\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m model, losses, train_acc, test_acc, epochs_converged, train_metrics, test_metrics, val_losses, train_acc_curve, test_acc_curve \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Calculate pattern presentations\u001b[39;00m\n\u001b[1;32m    257\u001b[0m num_presentations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m*\u001b[39m epochs_converged\n",
      "Cell \u001b[0;32mIn[14], line 134\u001b[0m, in \u001b[0;36mRegressionModelEvaluator._train_model\u001b[0;34m(self, X_train, y_train_idx, X_test, y_test_idx, params, epochs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    133\u001b[0m     val_outputs \u001b[38;5;241m=\u001b[39m model(X_test)\n\u001b[0;32m--> 134\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# For regression, use negative MSE as \"accuracy\" (higher is better)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/modules/loss.py:616\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/nn/functional.py:3868\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction, weight)\u001b[0m\n\u001b[1;32m   3865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3866\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3868\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n",
      "File \u001b[0;32m~/.local/lib/python3.13/site-packages/torch/functional.py:48\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     handle_torch_function,\n\u001b[1;32m     15\u001b[0m     has_torch_function,\n\u001b[1;32m     16\u001b[0m     has_torch_function_unary,\n\u001b[1;32m     17\u001b[0m     has_torch_function_variadic,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matleast_1d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matleast_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munravel_index\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m ]\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbroadcast_tensors\u001b[39m(\u001b[38;5;241m*\u001b[39mtensors):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"broadcast_tensors(*tensors) -> List of Tensors\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Broadcasts the given tensors according to :ref:`broadcasting-semantics`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m                [0, 1, 2]])\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# This wrapper exists to support variadic args.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = RegressionModelEvaluator()\n",
    "\n",
    "# Fix y_tensor format - squeeze to remove extra dimensions\n",
    "y_for_eval = y_tensor.squeeze()\n",
    "\n",
    "# Run 50 trials with cross-validation\n",
    "print(\"Running 50 trials with best parameters and 5-fold cross-validation...\")\n",
    "print(f\"Data shapes: X={X_tensor.shape}, y={y_for_eval.shape}\")\n",
    "print(f\"Best params from original training: {best_params}\")\n",
    "print()\n",
    "\n",
    "passive_results = evaluator.evaluate_passive_learning(\n",
    "    X=X_tensor,\n",
    "    y=y_for_eval,  # Use properly formatted y\n",
    "    best_params=best_params,\n",
    "    n_trials=50,\n",
    "    use_cv=False, \n",
    "    cv_folds=5,\n",
    "    epochs=1000, \n",
    "    random_state=12,\n",
    ")\n",
    "\n",
    "# Print comprehensive report\n",
    "print(\"\\n\")\n",
    "evaluator.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb2bfca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
