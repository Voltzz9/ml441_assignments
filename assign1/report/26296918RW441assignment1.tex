\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, bottom=65pt, top=65pt, left=60pt, right=60pt]{geometry}
\usepackage[round]{natbib}
\usepackage{booktabs}
\usepackage{float}
\usepackage{amsmath}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{microtype}
\usepackage{longtable}
\usepackage[font=small]{caption}


\makeatletter
\renewcommand\maketitle
  {\noindent
   {\Large\bfseries\@title}%
   \medskip\par\noindent
   {\large\bfseries\@author}%
   \hfill
   {\large\@date}%
   \bigskip\par\noindent
  }
\makeatother


\setlength{\parindent}{0pt}

\title{Machine Learning 441 Assignment 1}
\author{David Nicolay (26296918)}
\date{6 August 2025}

\begin{document}


\maketitle
\endgraf\rule{\textwidth}{.8pt}

\section*{Task 1: Analytics Base Table}
\begin{enumerate}
	\item 581012
	\item 62
	\item Continuous features
\begin{table}[ht]
	\centering
	\caption{Data Quality Report for Continuous Features}
	\label{tab:cts_quality}
	
		\resizebox{\textwidth}{!}{%
	\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
		\hline
		\textbf{Feature} & \textbf{Count} & \textbf{\% Miss.} & \textbf{Card.} & \textbf{Min.} & \textbf{$1^{st}$ Qrt.} & \textbf{Mean} & \textbf{Median} & \textbf{$3^{rd}$ Qrt.} & \textbf{Max.} & \textbf{Std. Dev.} \\
		\hline
		1 & 581012 & 0.00 & 1978 & 2054845.65 & 3104928.15 & 3271134.43 & 3311628.60 & 3496222.05 & 4264440.30 & 309481.13 \\
		2 & 581012 & 0.51 & 361 & 0.00 & 58.00 & 155.66 & 127.00 & 260.00 & 360.00 & 111.91 \\
		3 & 581012 & 0.00 & 576099 & 0.00 & 145.49 & 389.92 & 318.12 & 652.53 & 903.48 & 280.34 \\
		4 & 581012 & 0.05 & 67 & 0.00 & 9.00 & 14.10 & 13.00 & 18.00 & 66.00 & 7.49 \\
		5 & 581012 & 0.51 & 569 & -691.00 & 108.00 & 269.42 & 218.00 & 384.00 & 1397.00 & 212.56 \\
		6 & 581012 & 0.00 & 581012 & -173.07 & 6.99 & 46.42 & 29.91 & 68.97 & 600.95 & 58.30 \\
		7 & 581012 & 0.51 & 577988 & -1.00 & -0.50 & -0.00 & -0.00 & 0.50 & 1.00 & 0.58 \\
		8 & 581012 & 0.00 & 5811 & 0.00 & 1106.00 & 8158.11 & 1997.00 & 3328.00 & 510165098.00 & 1185156.02 \\
		9 & 581012 & 0.51 & 207 & 0.00 & 198.00 & 212.14 & 218.00 & 231.00 & 254.00 & 26.77 \\
		11 & 581012 & 0.00 & 255 & 0.00 & 119.00 & 142.53 & 143.00 & 168.00 & 254.00 & 38.27 \\
		12 & 581012 & 0.51 & 5826 & 0.00 & 1024.00 & 1980.43 & 1710.00 & 2550.00 & 7173.00 & 1324.25 \\
		61 & 581012 & 0.00 & 581012 & 1.00 & 145253.75 & 290506.50 & 290506.50 & 435759.25 & 581012.00 & 167723.86 \\
		\hline
	\end{tabular}
}
\end{table}

\begin{table}[ht]
	\caption{Categorical Data Quality Report}
	\label{tab:categorical_quality}
	\resizebox{\textwidth}{!}{%
	\begin{tabular}{|l|r|r|r|l|r|r|l|r|r|}
		\hline
		\textbf{Feature} & \textbf{Count} & \textbf{\%miss }& \textbf{Card.} & \textbf{Mode} & \textbf{Mode Freq.} & \textbf{Mode \%} & \textbf{$2^{nd}$ Mode} & \textbf{$2^{nd}$ Mode Freq} & \textbf{$2^{nd}$ Mode \%} \\
		\hline
		10 & 578069 & 0.51 & 186 & 231 & 13482 & 2.33 & 228 & 13474 & 2.33 \\
		13 & 578069 & 0.51 & 2 & 0.00 & 318579 & 55.11 & 1.00 & 259490 & 44.89 \\
		14 & 581012 & 0.00 & 2 & 0 & 551128 & 94.86 & 1 & 29884 & 5.14 \\
		15 & 581012 & 0.00 & 2 & 0 & 327648 & 56.39 & 1 & 253364 & 43.61 \\
		16 & 578069 & 0.51 & 1 & 0.00 & 578069 & 100.00 &  & 0 & 0.00 \\
		17 & 581012 & 0.00 & 1 & 0 & 581012 & 100.00 &  & 0 & 0.00 \\
		18 & 578069 & 0.51 & 3 & 0.00 & 538608 & 93.17 & 1.00 & 36589 & 6.33 \\
		19 & 581012 & 0.00 & 2 & 0 & 291278 & 50.13 & 1 & 289734 & 49.87 \\
		20 & 577566 & 0.59 & 2 & 0.00 & 574553 & 99.48 & 1.00 & 3013 & 0.52 \\
		21 & 173355 & 70.16 & 2 & 0.00 & 172455 & 99.48 & 1.00 & 900 & 0.52 \\
		22 & 581012 & 0.00 & 2 & 0 & 573487 & 98.70 & 1 & 7525 & 1.30 \\
		23 & 581012 & 0.00 & 2 & 0 & 576189 & 99.17 & 1 & 4823 & 0.83 \\
		24 & 581012 & 0.00 & 2 & 0 & 568616 & 97.87 & 1 & 12396 & 2.13 \\
		25 & 581012 & 0.00 & 2 & 0 & 579415 & 99.73 & 1 & 1597 & 0.27 \\
		26 & 581012 & 0.00 & 2 & 0 & 574437 & 98.87 & 1 & 6575 & 1.13 \\
		27 & 581012 & 0.00 & 2 & 0 & 580907 & 99.98 & 1 & 105 & 0.02 \\
		28 & 581012 & 0.00 & 2 & 0 & 580833 & 99.97 & 1 & 179 & 0.03 \\
		29 & 581012 & 0.00 & 2 & 0 & 579865 & 99.80 & 1 & 1147 & 0.20 \\
		30 & 581012 & 0.00 & 2 & 0 & 548378 & 94.38 & 1 & 32634 & 5.62 \\
		31 & 581012 & 0.00 & 2 & 0 & 568602 & 97.86 & 1 & 12410 & 2.14 \\
		32 & 581012 & 0.00 & 2 & 0 & 551041 & 94.84 & 1 & 29971 & 5.16 \\
		33 & 581012 & 0.00 & 2 & 0 & 563581 & 97.00 & 1 & 17431 & 3.00 \\
		34 & 581012 & 0.00 & 2 & 0 & 580413 & 99.90 & 1 & 599 & 0.10 \\
		35 & 581012 & 0.00 & 2 & 0 & 581009 & 100.00 & 1 & 3 & 0.00 \\
		36 & 581012 & 0.00 & 2 & 0 & 578167 & 99.51 & 1 & 2845 & 0.49 \\
		37 & 581012 & 0.00 & 2 & 0 & 577590 & 99.41 & 1 & 3422 & 0.59 \\
		38 & 581012 & 0.00 & 2 & 0 & 579113 & 99.67 & 1 & 1899 & 0.33 \\
		39 & 581012 & 0.00 & 2 & 0 & 576991 & 99.31 & 1 & 4021 & 0.69 \\
		40 & 581012 & 0.00 & 2 & 0 & 571753 & 98.41 & 1 & 9259 & 1.59 \\
		41 & 581012 & 0.00 & 2 & 0 & 580174 & 99.86 & 1 & 838 & 0.14 \\
		42 & 581012 & 0.00 & 2 & 0 & 547639 & 94.26 & 1 & 33373 & 5.74 \\
		43 & 581012 & 0.00 & 2 & 0 & 523260 & 90.06 & 1 & 57752 & 9.94 \\
		44 & 581012 & 0.00 & 2 & 0 & 559734 & 96.34 & 1 & 21278 & 3.66 \\
		45 & 581012 & 0.00 & 2 & 0 & 580538 & 99.92 & 1 & 474 & 0.08 \\
		46 & 581012 & 0.00 & 2 & 0 & 578423 & 99.55 & 1 & 2589 & 0.45 \\
		47 & 581012 & 0.00 & 2 & 0 & 579926 & 99.81 & 1 & 1086 & 0.19 \\
		48 & 581012 & 0.00 & 2 & 0 & 580066 & 99.84 & 1 & 946 & 0.16 \\
		49 & 581012 & 0.00 & 2 & 0 & 465765 & 80.16 & 1 & 115247 & 19.84 \\
		50 & 581012 & 0.00 & 2 & 0 & 550842 & 94.81 & 1 & 30170 & 5.19 \\
		51 & 581012 & 0.00 & 2 & 0 & 555346 & 95.58 & 1 & 25666 & 4.42 \\
		52 & 581012 & 0.00 & 2 & 0 & 528493 & 90.96 & 1 & 52519 & 9.04 \\
		53 & 581012 & 0.00 & 2 & 0 & 535858 & 92.23 & 1 & 45154 & 7.77 \\
		54 & 581012 & 0.00 & 2 & 0 & 579401 & 99.72 & 1 & 1611 & 0.28 \\
		55 & 581012 & 0.00 & 2 & 0 & 579121 & 99.67 & 1 & 1891 & 0.33 \\
		56 & 581012 & 0.00 & 2 & 0 & 580893 & 99.98 & 1 & 119 & 0.02 \\
		57 & 581012 & 0.00 & 2 & 0 & 580714 & 99.95 & 1 & 298 & 0.05 \\
		58 & 581012 & 0.00 & 2 & 0 & 565439 & 97.32 & 1 & 15573 & 2.68 \\
		59 & 581012 & 0.00 & 2 & 0 & 567206 & 97.62 & 1 & 13806 & 2.38 \\
		60 & 581012 & 0.00 & 2 & 0 & 572262 & 98.49 & 1 & 8750 & 1.51 \\
		62 & 581012 & 0.00 & 1 & 1 & 581012 & 100.00 &  & 0 & 0.00 \\
		\hline
	\end{tabular}
}

\end{table}


	\item Target feature data quality report:
	\begin{table}[H]
		\caption{Data Quality Report for target feature}
		\label{tab:data_quality}
			\resizebox{\textwidth}{!}{%
		\begin{tabular}{|l|r|r|r|r|r|r|r|r|r|r|}
			\hline
			\textbf{Feature} & \textbf{Count} & \textbf{\%miss }& \textbf{Card.} & \textbf{Mode} & \textbf{Mode Freq.} & \textbf{Mode \%} & \textbf{$2^{nd}$ Mode} & \textbf{$2^{nd}$ Mode Freq} & \textbf{$2^{nd}$ Mode \%}  \\
			\hline
			$T$ & 581012 & 0.00 & 7 & 2.00 & 283269 & 48.75 & 1.00 & 211815 & 36.46\\
			\hline
		\end{tabular}
	}
	\end{table}

\end{enumerate}


\section*{Task 2: Data Quality Issues}
\begin{table}[H]
	\centering
	\label{tab:feature_quality_issues}
	\begin{tabular}{|p{1.7cm}|l|p{8cm}|}
		\hline
		\textbf{Feature} & \textbf{Data Quality Issue} & \textbf{Justification} \\
		\hline
		A2 & Missing Values & Many records have missing values for A2 as observed in Table~\ref{tab:cts_quality}. There are 0.51\% of the observations with A2 missing. \\
		\hline
		A2, A3 & Perfect Correlation & The features A2 and A3 are perfectly correlated as observed in Figure~\ref{fig:heatmap}. This means that they are an \textit{exact} linear transformation of each other.\\
		\hline
		A4, A5, A7, A9, A10, A12, A13, A16, A18, A20, A21 & Missing Values & Testing revealed that there is a certain 2947 rows with all these features missing simultaneously. \\
		\hline
		A8 & Extreme outliers / skew & The maximum value of this feature is much higher than the mean and the 3rd quartile, indicating that there may be an error. The extreme nature of these outliers is shown in Figure~\ref{fig:f8}. Through testing it was found that there are 18 observations greater than 50,000,000 with the 99.9th percentile sitting at 6699.0.\\
		\hline
		A9, A11 & Strongly Correlated Features & Figure~\ref{fig:heatmap} indicates that A9 and A11 are strongly correlated with a coefficient of  -0.78. After further investigation, we observed that there is likely a mathematical or physical constraint between the two features due to the relationship exhibited in Figure~\ref{fig:A9_A11_scatter}.\\
		\hline
		A10 & Abnormal Data Type & There are 0.99\% of the observations in feature A10 that have the value 'a' whilst all the other observations have numerical values. \\
		\hline
		A16 & Cardinality of 1 & This categorical variable is redundant since all the observations have the same value.  \\
		\hline
		A17 & Cardinality of 1 & This categorical variable is redundant since all the observations have the same value. \\
		\hline
		A21 & Missing Values & Many records, specifically 70.16\% have missing values for A21 as observed in Table~\ref{tab:categorical_quality}. \\
		\hline
		A35 & Class imbalance & The 2nd class for this feature only has 3 observations. This rounds down to 0.00\% shown in Table~\ref{tab:categorical_quality}. \\
		\hline
		A61 & ID Feature & This feature has a perfectly uniform distribution observed in Figure~\ref{fig:f61}. Testing revealed that the feature value is exactly the same row number for all observations. \\
		\hline
		A61, A1 & Strongly Correlated Features & The features A1 and A61 are strongly correlated, as observed in Figure~\ref{fig:heatmap} with a correlation coefficient of -0.95. \\
		\hline
		A62 & Cardinality of 1 & This categorical variable is redundant since all the observations have the same value. \\
		\hline
	\end{tabular}
\end{table}

\begin{figure}[H]
	\centering
	
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/8_distribution.pdf}
		\caption{Feature 8 distribution with 100 bins}
		\label{fig:f8}
	\end{minipage}
	\hfill
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/61_distribution.pdf}
		\caption{Feature 61 distribution with 100 bins}
		\label{fig:f61}
	\end{minipage}
	
\end{figure}



\section*{Task 3: Addressing The Data Quality Issues}
\begin{longtable}{|p{1.7cm}|l|p{3cm}|p{6cm}|}
	\caption{Data Quality Fixes} \label{tab:feature_quality_fixes} \\
	\hline
	\textbf{Feature} & \textbf{Data Quality Issue} & \textbf{Handling Strategy} & \textbf{Justification} \\
	\hline
	\endfirsthead
	
	\multicolumn{4}{c}{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
	\hline
	\textbf{Feature} & \textbf{Data Quality Issue} & \textbf{Handling Strategy} & \textbf{Justification} \\
	\hline
	\endhead
	
	\hline \multicolumn{4}{r}{{Continued on next page}} \\
	\endfoot
	
	\hline
	\endlastfoot
	A2 & Missing Values & Remove Feature & See below. \\ \hline
	A2, A3 & Perfect Correlation & Remove Feature A2 & Since the features are perfectly correlated, we are essentially storing the same information twice which provides no value to a machine learning model. Since A2 has missing values we might as well remove it to deal with two quality issues at the same time. \\ \hline
	A4, A5, A7, A9, A10, A12, A13, A16, A18, A20, A21 & Missing Values & Remove Observations & Since testing revealed that there is a certain 2947 rows with all these features missing simultaneously, it makes sense to simply remove all these observations since they have a large amount of missing information. It is useful to note that the distribution of the target variable in these observations matches the overall distribution of the target variable for the whole dataset observed in Figure~\ref{fig:target_dist}. This means that we are likely not losing useful information about a certain feature when removing these observations.  \\ \hline
	A8 & Outlier observations & Observation removal & There must be an error with the observations in question because the outliers are so incredibly skewed. Through testing it was found that there are 18 observations greater than 50,000,000 with the 99.9th percentile sitting at 6699.0. \\ \hline
	A9, A11 & Strongly Correlated Features & Nothing & Despite these features being strongly correlated, there is still a chance that the features' relationship represents makes sense in the domain context. Therefore we elect to not remove either feature.\\ \hline
	A10 & Abnormal Data Type & Imputation & Testing revealed that the levels of this suspected categorical variable range from 100â€“254 predominantly. Since many observations have the value 'a', we can guess this error is not at random and the character 'a' should be replaced by 255. This fits the distribution seen in Figure~\ref{fig:f10}. \\ \hline
	A16 & Cardinality of 1 & Drop Feature & This categorical variable can be removed since it will have no effect on a model's performance. \\ \hline
	A17 & Cardinality of 1 & Drop Feature & This categorical variable can be removed since it will have no effect on a model's performance. \\ \hline
	A21 & Missing Values & Drop Feature & Testing revealed that the correlation between missingness of A21 and the target is -0.0004. Due to the high number of missing values we should remove the feature. \\ \hline
	A35 & Class imbalance & Drop Feature & Since there are only three observations in the second class for this feature, it should be removed without affecting model performance. \\ \hline
	A61 & ID Feature & Drop Feature & It was confirmed this feature perfectly fits the description of an ID column, meaning it has no predictive power and can be removed. \\ \hline
	A61, A1 & Strongly Correlated Features & Drop Feature & Since we have already established that A61 is a redundant ID feature and have determined to remove it, we have solved the issue. \\ \hline
	A62 & Cardinality of 1 & Drop Feature & This categorical variable can be removed since it will have no effect on a model's performance. \\ \hline
	
\end{longtable}

	
\begin{figure}[H]
	\centering
	\begin{minipage}[t]{\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/2_distribution.pdf}
		\caption{Feature 2 distribution with 100 bins}
		\label{fig:f2}
	\end{minipage}
	
	\vspace{1em} % space between plots
	
	\begin{minipage}[t]{\textwidth}
		\centering
		\includegraphics[width=\textwidth]{images/10_distribution.pdf}
		\caption{Feature 10 distribution ordered by value}
		\label{fig:f10}
	\end{minipage}
\end{figure}





\begin{figure}[H]
	\centering
	% First plot (heatmap)
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/correlation_matrix_heatmap.pdf}
		\caption{Correlation heatmap}
		\label{fig:heatmap}
	\end{minipage}
	\hfill
	% Second plot (scatter)
	\begin{minipage}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{images/A9_A11_scatter.pdf}
		\caption{A9 vs A11 scatter plot}
		\label{fig:A9_A11_scatter}
	\end{minipage}
\end{figure}

\begin{figure}[H]
		\centering
	\includegraphics[width=\textwidth]{images/target_feature_distribution.pdf}
	\caption{Target value distribution comparison}
	\label{fig:target_dist}
\end{figure}


%	\begin{minipage}{0.4\textwidth}
%		\begin{figure}[H]
%			\centering
%			\includegraphics[width=\linewidth]{images/A2_vs_A3_scatter.pdf}
%			\caption{Scatter plot of A2 vs A3}
%			\label{fig:A2_vs_A3_scatter}
%		\end{figure}
%	\end{minipage}






%\bibliographystyle{plainnat}
%\bibliography{references}


\end{document}
